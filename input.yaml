activation: silu
aggr: add
atom_filter: -1
attn_activation: silu
batch_size: 128
box_vecs: null
charge: false
check_errors: true
coord_files: null
cutoff_lower: 0.0
cutoff_upper: 5.0
dataset: QM9
dataset_arg:
  label: energy_U0
dataset_preload_limit: 1024
dataset_root: ~/data
derivative: false
distance_influence: both
early_stopping_patience: 150
ema_alpha_neg_dy: 1.0
ema_alpha_y: 1.0
embed_files: null
embedding_dimension: 256
energy_files: null
equivariance_invariance_group: O(3)
force_files: null
gradient_clipping: 0.0
inference_batch_size: 128
load_model: null
log_dir: output/
lr: 0.0004
lr_factor: 0.8
lr_metric: val
lr_min: 1.0e-07
lr_patience: 15
lr_warmup_steps: 10000
max_num_neighbors: 64
max_z: 100
model: equivariant-transformer
neg_dy_weight: 1.0
neighbor_embedding: true
ngpus: -1
num_epochs: 3000
num_heads: 8
num_layers: 8
num_nodes: 1
num_rbf: 64
num_workers: 6
output_mlp_num_layers: 0
output_model: Scalar
precision: 32
prior_model: Atomref
rbf_type: expnorm
redirect: false
reduce_op: add
remove_ref_energy: false
reset_trainer: false
save_interval: 10
seed: 1
spin: false
splits: null
standardize: false
static_shapes: false
tensorboard_use: false
test_interval: 10
test_size: null
train_loss: mse_loss
train_loss_arg: null
train_size: 110000
trainable_rbf: false
val_size: 10000
vector_cutoff: true
wandb_name: training
wandb_project: training_
wandb_resume_from_id: null
wandb_use: false
weight_decay: 0.0
y_weight: 1.0
